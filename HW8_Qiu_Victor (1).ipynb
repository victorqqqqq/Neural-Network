{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW8_Qiu_Victor.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UKC_0XpjztC"
      },
      "source": [
        "Homework 8 (20 marks)\n",
        "\n",
        "Create a copy of the notebook to start answering the questions. Name your notebook in the format HW8_lastname_firstname.ipynb to facilitate the grading process.\n",
        "Answer all the questions, test your code to ensure there are no errors and the results are as expected. Once you have answered all the questions, save the final copy, then go to File-> click on Download.ipynb. Once the local copy has been downloaded, submit your file on Blackboard under the corresponding assignment section. Also provide us a link to your notebook during submission.\n",
        "NOTE: Please give the TAs the permission to access your notebooks through the links you have provided during submission.\n",
        "The due date of this homework is 05/02/2021 (Sunday).\n",
        "Please ensure you follow all the steps mentioned in the homework.\n",
        "You can submit your solutions any number of times until the deadline.\n",
        " \n",
        "The format of this homework is slightly different from the other homeworks till now. Make sure you read every instruction correctly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZ4PbPiBOcGY"
      },
      "source": [
        "### Handwritten Digit Recognition "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogDw2JYdOm0b"
      },
      "source": [
        "For this project, we will be using the popular MNIST database. It is a collection of 70000 handwritten digits split into training and test set of 60000 and 10000 images respectively.\n",
        "\n",
        "PyTorch provides an easy implementation to download the cleaned and already prepared data.\n",
        "\n",
        "Please do not copy code from outside for the assignment. We recommend that you try the code on your own and understand the implementation. We will provide the necessary steps to be followed. It is a fairly simple assignment with less to code and more to understand:)\n",
        "\n",
        "Everything you need will be provided in the assignment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWojvqBlOfgN"
      },
      "source": [
        "# libraries needed\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "from time import time\n",
        "from torchvision import datasets, transforms\n",
        "from torch import nn, optim\n",
        "from torch.utils.tensorboard import SummaryWriter"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtjuHdvcVV52"
      },
      "source": [
        "We will perform some transformations on our data before feeding it into the neural network pipeline. Since the input data consists of images, we will do some pre-processing to convert all the images to a format that can be understood by the neural network. We do it using torchvision.transforms."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgYSmHHXVn1q"
      },
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                              transforms.Normalize((0.5,), (0.5,)),\n",
        "                              ])"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVVJJmowVqJK"
      },
      "source": [
        "- transforms.ToTensor() — converts the image into numbers, that are understandable by the network. It separates the image into three color channels (separate images): red, green & blue. Then it converts the pixels of each image to the brightness of their color between 0 and 255. These values are then scaled down to a range between 0 and 1. The image is now a Torch Tensor.\n",
        "- transforms.Normalize() — normalizes the tensor with a mean and standard deviation which goes as the two parameters respectively.\n",
        "\n",
        "The above code ensures that all our images have the same dimensions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rmVjMQWV36T"
      },
      "source": [
        "Now will download the data sets, shuffle them and transform each of them. We download the data sets and load them to DataLoader, which combines the data-set and a sampler and provides single- or multi-process iterators over the data-set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UE1kKSZiWJCg"
      },
      "source": [
        "Please enter the path to store your train and test data correctly in place of the 'PATH_TO_STORE_TRAINSET' and 'PATH_TO_STORE_TESTSET' respectively. \n",
        "\n",
        "This can either be the colab runtime in which case the path would be /content/. If not you can also store it to a location on drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXxu29-QWH5P"
      },
      "source": [
        "# give full path below\n",
        "trainset = datasets.MNIST('/content/', download=True, train=True, transform=transform)\n",
        "valset = datasets.MNIST('/content/', download=True, train=False, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "valloader = torch.utils.data.DataLoader(valset, batch_size=64, shuffle=True)\n",
        "\n",
        "# here batch size is the number of images we want to read in one go"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BeLvaMtHXo87"
      },
      "source": [
        "Next, we will do some exploratory data analysis on our images and tensors. Let us check out the shape of the images and the labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JX0rQx9GXvLV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80e8c589-413a-4b84-c16c-35b4e88ed4e3"
      },
      "source": [
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "print(images.shape)\n",
        "print(labels.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuWTk4WtX8SS"
      },
      "source": [
        "The shape of images as you’ll find out is, torch.Size([64,1,28,28]), which suggests that there are 64 images in each batch and each image has a dimension of 28 x 28 pixels.\n",
        "\n",
        "Similarly, the labels have a shape as torch.Size([64]). This is because the 64 images should have 64 labels respectively. That’s it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4mEL1KTYInn"
      },
      "source": [
        "Now let us view one image from the training set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4n278HTX71H",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "cb13c06a-0268-44b3-c01a-9a1e59df775e"
      },
      "source": [
        "plt.imshow(images[0].numpy().squeeze(), cmap='gray_r')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7ff7625ca910>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MIv8n3QYSU9"
      },
      "source": [
        "Next, let us view a bunch of images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdPSJGx3YXrI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "outputId": "9be0a810-b750-4237-e97a-076c5e50d66e"
      },
      "source": [
        "figure = plt.figure()\n",
        "num_of_images = 20\n",
        "for index in range(1, num_of_images + 1):\n",
        "    plt.subplot(2, 10, index)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(images[index].numpy().squeeze(), cmap='gray_r')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 20 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGJy4RXGYlsx"
      },
      "source": [
        "This will generate a grid of images in a random order. \n",
        "\n",
        "Now, let us define our neural network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xxh8qFGZYsqT"
      },
      "source": [
        "We will be building the following network. This network contains an input layer (the first layer), an output layer of ten neurons (or units, the circles) and two hidden layers in between.\n",
        "\n",
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQUSper8Y3gZ"
      },
      "source": [
        "Build the above model in PyTorch.\n",
        "\n",
        "Use nn.Sequential to start. There are three linear layers with ReLU activation ( a simple function which allows positive values to pass through, whereas negative values are modified to zero). The output layer is a linear layer with LogSoftmax activation because this is a classification problem.\n",
        "\n",
        "We have 784 units in the first layer. It is because we flatten out each image before sending it inside the neural network. (28 x 28 = 784)\n",
        "\n",
        "The first hidden layer size is 128. This is followed by a ReLU activation. This is passed through another hidden layer of size 64, which is followed by a ReLU activation. You have another linear layer with an output of size 10. This layer is followed by the LogSoftMax activation. (Google LogSoftMax for usage, dim should be set to 1.)\n",
        "\n",
        "Complete the TODO part of the code below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSoNRJ65GVp4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bb7900a-a718-4d10-833b-bebeac372142"
      },
      "source": [
        "# type code here\n",
        "\n",
        "from torch import nn\n",
        "\n",
        "# TODO: start your model here (4 marks)\n",
        "model = nn.Sequential(nn.Linear(784,128),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(128,64),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(64,10),\n",
        "                      nn.LogSoftmax(dim=1))\n",
        "\n",
        "\n",
        "#  TODO: print your model (1 mark)\n",
        "print(model)\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=784, out_features=128, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (3): ReLU()\n",
            "  (4): Linear(in_features=64, out_features=10, bias=True)\n",
            "  (5): LogSoftmax(dim=1)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaVEJKvBGOoJ"
      },
      "source": [
        "Next, we will define the negative log-likelihood loss. It is useful to train a classification problem with C classes. Together the LogSoftmax() and NLLLoss() acts as the cross-entropy loss as shown in the network architecture diagram above. Complete only the TODO parts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFKQQWyBGSV8"
      },
      "source": [
        "# Insert code wherever asked. Do not alter any other part of the code.\n",
        "\n",
        "# assign criterion to negative log-likelihood loss (check the pytorch documentation for usage)\n",
        "\n",
        "criterion = nn.NLLLoss()# TODO: your answer (1 mark)\n",
        "\n",
        "images, labels = next(iter(trainloader))\n",
        "images = images.view(images.shape[0], -1)\n",
        "\n",
        "logps = model(images) #log probabilities\n",
        "loss = criterion(logps, labels) #calculate the NLL loss"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6IdN6MEtl25"
      },
      "source": [
        "Now to train the network, the neural network iterates over the training set and updates the weights. We make use of torch.optim which is a module provided by PyTorch to optimize the model, perform gradient descent and update the weights by back-propagation. Thus in each epoch (number of times we iterate over the training set), we will be seeing a gradual decrease in training loss.\n",
        "\n",
        "Complete the below code only in the TODO parts of the code in order to setup the training loop. Do not modify anything else in the code.\n",
        "\n",
        "The below code may take a while to run as the data is large.\n",
        "\n",
        "You will also be adding code to generate the tensorboard logs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrlDeVVMeNcJ"
      },
      "source": [
        "# TODO: Add code to integrate tensorboard here (2 marks)\n",
        "\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "writer = SummaryWriter()"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hi7B9fKRt-Pq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17a03dbe-8fa9-4002-9c18-0042e3e45f57"
      },
      "source": [
        "# TODO: Initialize a SGD optimizer with a learning rate of 0.001 and momentum of 0.5. Use the same optimizer variable given.\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.5) # TODO your code here (1 mark)\n",
        "\n",
        "time0 = time()\n",
        "epochs = 15\n",
        "\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    for images, labels in trainloader:\n",
        "        # Flatten MNIST images into a 784 long vector\n",
        "        images = images.view(images.shape[0], -1)\n",
        "\n",
        "        # TODO: Add the code to perform the training pass, predict the output, compute loss, perform backpropagation and optimize the weights.\n",
        "\n",
        "        # TODO: Forward pass - add code below - clear the gradients, do this because gradients are accumulated (1 mark)\n",
        "        optimizer.zero_grad()\n",
        "        # predictions -- code is given, do not modify it\n",
        "        output = model(images)\n",
        "\n",
        "        # TODO: Compute and print loss - use the loss function initialized above (2 mark)\n",
        "        loss = criterion(output, labels)\n",
        "        print('loss:',loss)\n",
        "        # TODO: Add the loss to the tensorboard summary writer (1 mark)\n",
        "        writer.add_scalar('loss',loss)\n",
        "        # TODO: This is where the model learns by backpropagating - Backward pass: compute gradient of the loss with respect to model parameters\n",
        "        # (1 mark)\n",
        "        loss.backward()\n",
        "        # TODO: And optimizes its weights here - Calling the step function on an Optimizer makes an update to its parameters\n",
        "        # (1 mark)\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    else:\n",
        "        print(\"Epoch {} - Training loss: {}\".format(e, running_loss/len(trainloader)))\n",
        "print(\"\\nTraining Time (in minutes) =\",(time()-time0)/60)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "loss: tensor(0.4310, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1602, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3609, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2382, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2345, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2298, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2257, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2845, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5073, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2174, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2751, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2043, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4230, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2042, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4067, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3223, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2580, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.6093, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4674, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3713, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3386, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3040, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2891, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5706, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5173, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3568, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3796, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2188, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2869, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2363, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5264, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3201, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4941, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3773, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2326, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5015, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4887, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3028, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2710, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2901, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4603, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4302, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4189, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3693, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3697, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4397, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3083, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4252, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2981, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3091, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2475, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2708, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4368, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2967, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2808, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3258, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2822, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4102, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4289, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3648, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3093, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2900, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3373, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3437, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4338, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4078, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3376, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2505, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3084, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3630, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5267, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2726, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3851, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1051, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3441, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3212, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4852, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2924, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2866, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1602, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2515, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2090, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2932, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5007, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4185, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4377, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3115, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3721, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4778, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4993, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2556, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3255, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2346, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3500, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.6194, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3373, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2898, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3123, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4252, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3296, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2507, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2693, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4002, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3519, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4684, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3010, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4696, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3160, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3516, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2851, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3677, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3205, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2714, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3616, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3877, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5826, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3404, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2672, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4358, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.7144, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4817, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3486, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4317, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5321, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4965, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1983, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4540, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2158, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3190, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4839, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1366, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4509, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.6661, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4849, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3653, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4213, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2844, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2051, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3516, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5066, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4315, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3408, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2428, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3951, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3727, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3544, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2354, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3067, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2754, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5486, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2350, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4162, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2993, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3979, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2950, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3609, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2269, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3891, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4916, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3850, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2458, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2352, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3170, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3414, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3144, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2402, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3342, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2746, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3786, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4434, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3066, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3435, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5080, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4252, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3784, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2234, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2909, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3363, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4721, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3685, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3658, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5071, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4103, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3666, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3281, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3964, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3183, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2137, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3379, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3802, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3707, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2832, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4225, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4213, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3429, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3889, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2451, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3003, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4378, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3632, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2545, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3756, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3923, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3533, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2804, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2457, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3866, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2517, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3907, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5986, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2557, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3426, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3264, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3113, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3666, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4394, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3204, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1858, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3869, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2343, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1705, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2795, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2129, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3655, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4156, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2864, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1768, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3116, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3176, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3396, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2379, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3488, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4436, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3138, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2830, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4666, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3039, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3907, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3771, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3082, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5040, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2683, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4238, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3798, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2903, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3514, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3021, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2860, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3012, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2851, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3686, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3582, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2327, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2650, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4968, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3868, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4514, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3187, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3779, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3775, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3331, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4248, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2224, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2569, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.6909, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2667, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3332, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3973, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1770, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2507, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3570, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3016, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4340, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4021, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2314, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2564, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3209, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4721, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2313, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2702, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4854, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3922, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3587, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2004, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3346, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2865, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4592, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3094, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2544, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.6253, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1940, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3054, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4334, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3977, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2427, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2858, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2090, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3061, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4457, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3082, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3232, grad_fn=<NllLossBackward>)\n",
            "Epoch 9 - Training loss: 0.34158032320773424\n",
            "loss: tensor(0.3504, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5088, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1391, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3728, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4669, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2051, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3838, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5480, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4017, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2505, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5930, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3693, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3842, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3793, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4309, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4905, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2615, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2612, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3268, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2083, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4976, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4274, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3200, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3458, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2914, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2108, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2137, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3384, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2292, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4737, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1659, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3820, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2560, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3862, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3713, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2619, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4015, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3269, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2208, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3544, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3292, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4125, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4039, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3257, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3945, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4089, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4357, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2301, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3018, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2337, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3216, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2188, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3085, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3543, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4754, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3588, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3087, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2795, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4221, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3734, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3249, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2567, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2636, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2562, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3394, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1610, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3497, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3993, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3322, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3638, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2538, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2737, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1995, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4118, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2742, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4794, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3212, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3683, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3128, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4414, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3550, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3606, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2920, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3504, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2827, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2606, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3653, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2377, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5537, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3309, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1547, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2434, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2777, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2174, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4998, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4210, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3508, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2961, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3352, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3261, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3908, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2837, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2492, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3168, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2792, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2706, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4446, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3399, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3490, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3395, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2520, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2764, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3046, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3030, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3940, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2095, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3112, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5494, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4760, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2835, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2907, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3643, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2992, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3926, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1871, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2433, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2511, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2778, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2677, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2943, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2872, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2996, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3422, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2144, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1804, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2287, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3048, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3420, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2619, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3918, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4146, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1732, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3324, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2013, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4300, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3107, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2095, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3898, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2117, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2021, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1383, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4304, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2813, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2076, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2737, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2915, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2886, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4437, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4698, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2605, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3732, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2605, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2667, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2835, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3919, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3263, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2966, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2714, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2870, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1856, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3253, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2778, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4175, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3432, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3034, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3445, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4664, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3962, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4790, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2789, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3480, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4040, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4870, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3085, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5392, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2876, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2152, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3052, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2661, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2877, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3926, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1800, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2653, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2299, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3701, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2595, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3931, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4139, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2113, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2870, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3514, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4216, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1081, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2746, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5586, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3183, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4533, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4503, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3488, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2358, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3954, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3664, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3224, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3692, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2275, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4242, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2943, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3472, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2077, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3383, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3094, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4232, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3487, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2238, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4200, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4402, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3646, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3727, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3300, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2572, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5108, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2865, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5896, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3876, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3612, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2753, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5673, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1992, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5090, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2801, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3254, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3003, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3182, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2931, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1402, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1290, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2741, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.6511, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2385, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2305, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5795, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2766, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2779, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2473, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2935, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1864, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3199, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3079, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3905, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4106, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3416, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3162, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3343, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5553, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2314, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2732, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3105, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4135, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2890, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2951, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3528, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3566, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1512, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2627, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2996, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2228, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2869, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3872, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1773, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5252, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2200, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4194, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3232, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2026, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5425, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3051, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2903, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3716, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3306, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4504, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3331, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2845, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.6244, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5480, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1917, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4219, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3134, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1573, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2873, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3332, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1989, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4988, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3417, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4768, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2872, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2435, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3002, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4534, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2909, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2076, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3586, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5274, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3372, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3148, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4465, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3156, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2700, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.6431, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1918, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3513, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4045, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2520, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3264, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4285, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1824, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4733, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.8719, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3747, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3795, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2640, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2022, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2903, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5035, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4529, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1395, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2676, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2751, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4021, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2973, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2529, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2156, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4190, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2451, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3063, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3604, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2290, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2246, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2739, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2861, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3352, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2660, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3536, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2008, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4634, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2390, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2388, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2580, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3513, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5102, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1723, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2833, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2888, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3604, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4100, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4643, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2911, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5058, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3433, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4513, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4445, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3214, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2343, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2156, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1858, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4770, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3300, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2506, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1570, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2132, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3503, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2162, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1722, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1683, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3951, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4326, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3589, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4005, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3143, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4019, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2834, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3325, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3132, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1979, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4233, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4852, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4182, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4529, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4397, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4028, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3542, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3079, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3842, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2943, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2398, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4454, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4178, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1287, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2880, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5021, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3856, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2056, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3213, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2608, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1464, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3236, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1635, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2845, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3995, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2057, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2708, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4086, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4594, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4293, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2999, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2606, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3025, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2407, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2190, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3112, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3751, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5806, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3344, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3621, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3306, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.6082, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2867, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4269, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5505, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2432, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3475, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3060, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4706, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3226, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3343, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3698, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3673, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3646, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2634, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1702, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3220, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3808, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3911, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4804, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3039, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4285, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2173, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2969, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2067, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3367, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3816, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3856, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1591, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3620, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3479, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1976, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.6431, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2363, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3213, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3789, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5559, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2594, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3568, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2614, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3050, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4401, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4749, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4107, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3032, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2750, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2461, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3054, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1585, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2938, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3579, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2793, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4034, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4051, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2918, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3162, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3437, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3410, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3654, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2355, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2416, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3983, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1673, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4315, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2876, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4430, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2988, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2963, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3329, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2201, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4934, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5506, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5164, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3340, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2982, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4118, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3137, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3860, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1586, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3773, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2832, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4039, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3744, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3125, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4103, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2759, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2274, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2036, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3767, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3597, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3358, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3394, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2962, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2413, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2892, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4107, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4655, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3085, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2594, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1528, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2574, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4200, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2423, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3729, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2562, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2984, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2296, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3690, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3880, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3328, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3365, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2664, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1941, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1575, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3521, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1578, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2005, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2510, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1489, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5274, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1635, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2688, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2713, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5225, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3458, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3595, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4533, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4825, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3022, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4103, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2264, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4097, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5244, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2775, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3115, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4362, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3502, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.6342, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2264, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3475, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3006, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2120, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4446, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4258, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3660, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1948, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3060, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5502, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3685, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2714, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2657, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3670, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4120, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4630, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1675, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4483, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2639, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3357, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2721, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3627, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2829, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2289, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1752, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4966, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2872, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3701, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2080, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3409, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2907, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3610, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4776, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2568, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3409, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2463, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4465, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3264, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3803, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4914, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2578, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2955, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3430, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3756, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3954, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3241, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2499, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3454, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.6336, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2541, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2041, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2583, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4014, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2950, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3359, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3370, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3770, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3188, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2564, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2842, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2069, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3708, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2015, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5378, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5213, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2983, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3297, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3054, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1951, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2607, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3008, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2534, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3634, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.6559, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2910, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2325, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2195, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3150, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3015, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3709, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2263, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2346, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2349, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5667, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3179, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2346, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3417, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3322, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2220, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4695, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3314, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1904, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3183, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3161, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3767, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2968, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2997, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2929, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2177, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3404, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3008, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2183, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5031, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2592, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5539, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2769, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2478, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1212, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5317, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4581, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2492, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2195, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4536, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2192, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2987, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4414, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2915, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4766, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3733, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2075, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2820, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4798, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3026, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2075, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2869, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2775, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5148, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3336, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3605, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1744, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3205, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3805, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3030, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3484, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3667, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1416, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2428, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3184, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4802, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3175, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3167, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3706, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3402, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2661, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3153, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3131, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4828, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1839, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3706, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2205, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4617, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3678, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3444, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3300, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3496, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3566, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2363, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3230, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2221, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3826, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2620, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2604, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3090, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2843, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3436, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2589, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2309, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2975, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2865, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2851, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3957, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3258, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5133, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3683, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4601, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3184, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2832, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2529, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2909, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2343, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2724, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3398, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2938, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3126, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3650, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5055, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2004, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4664, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3664, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3653, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1166, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3320, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3975, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3414, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1827, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3013, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1740, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2688, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2606, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3653, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1797, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4380, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2953, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5041, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2878, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4063, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1879, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2874, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5225, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3583, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5631, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2688, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3022, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1470, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4121, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2030, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3350, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3478, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1809, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3265, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2058, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3401, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2715, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3597, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3260, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4707, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2719, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5260, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5209, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4836, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2986, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2332, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3284, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1869, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2476, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2777, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3716, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4568, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3354, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3284, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1383, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4952, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1794, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3899, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2303, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3417, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3143, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3282, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2079, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.6362, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2810, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5167, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3129, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1489, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2674, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2092, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2964, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3865, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3376, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3235, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3112, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3070, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2571, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3225, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5500, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4882, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4451, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2092, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3200, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4776, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2264, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.6278, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3088, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2927, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3786, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3073, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3335, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3988, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3111, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2947, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2750, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2165, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3319, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3110, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3697, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3190, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3379, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3097, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3923, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3165, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4605, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3690, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3447, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3737, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4467, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3396, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2917, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3688, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3479, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3545, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1706, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1747, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2153, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3994, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4686, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1907, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4026, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1870, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2224, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3926, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2476, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3490, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4242, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2310, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3975, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1915, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3156, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2988, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3669, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3958, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3695, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3933, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3317, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2767, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2844, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2222, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2425, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4931, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5634, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.6615, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3357, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3079, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3729, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4787, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2649, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3489, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3632, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2567, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3470, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3067, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2905, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5033, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3439, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2560, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3549, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2669, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3064, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4289, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4064, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1959, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4782, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3807, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5875, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3469, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3563, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2182, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1261, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3040, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2879, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2764, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2538, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3461, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3535, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4166, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3556, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4390, grad_fn=<NllLossBackward>)\n",
            "Epoch 10 - Training loss: 0.3306013455094178\n",
            "loss: tensor(0.2021, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4305, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3631, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5302, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1474, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3233, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3659, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4912, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3197, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3123, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4485, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3408, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4270, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2967, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3194, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3141, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2540, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2271, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4687, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3024, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4040, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3325, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2981, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3666, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2925, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2779, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4745, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3905, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3476, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2799, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.6322, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3809, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2122, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3394, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2606, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2557, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3744, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2392, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2845, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3363, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3238, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3088, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2343, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2855, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3577, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5647, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4383, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3400, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3129, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3036, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1401, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3808, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2532, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2749, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2681, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5595, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2486, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3286, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2499, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2407, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3436, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2557, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2958, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5963, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4157, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2275, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1737, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2839, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4604, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5464, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1403, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2209, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2123, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1600, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3042, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3532, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2756, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2090, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1692, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3544, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2304, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2872, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3299, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3295, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2366, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2996, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2960, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3188, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3420, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1486, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4160, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4313, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2092, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3039, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3092, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4476, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3532, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4589, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1773, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4554, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4035, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2182, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3232, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3559, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4493, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3168, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2888, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2479, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3033, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2093, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3315, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2147, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4134, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5332, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3088, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2562, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1897, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1854, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3862, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1884, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3832, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2739, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3040, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3559, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2790, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3343, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2793, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2942, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2777, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1680, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3668, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2107, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2854, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2157, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4123, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3711, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5502, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2203, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2922, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2909, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2390, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3128, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4394, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4693, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2981, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3283, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3347, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4825, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3484, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3632, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2835, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5993, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2349, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2096, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4670, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3990, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2765, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2750, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3690, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3659, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3235, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3158, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2647, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2451, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1947, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4340, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2614, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2732, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3538, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1940, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1563, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4039, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3791, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2792, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4254, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3591, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4015, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3926, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4218, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4303, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5169, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2588, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1753, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2720, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4135, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3105, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3005, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3319, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2804, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2385, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1806, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3303, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3836, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2240, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4013, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2442, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2651, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4434, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3476, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1991, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4058, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3453, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2138, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1829, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2421, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2697, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3261, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3786, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3218, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3137, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3962, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4012, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4400, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2423, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2020, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.6248, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1402, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1926, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2213, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3352, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2858, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2617, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3618, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3590, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3173, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.6564, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3945, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3167, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2115, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4302, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3542, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3178, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3721, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2747, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2172, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3666, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3860, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4807, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4176, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.9063, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4161, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3283, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2924, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2124, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4549, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3317, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3148, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1798, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4591, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2572, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3199, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1503, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1717, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2970, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3015, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3457, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2031, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1861, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3028, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1799, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3243, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4240, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3376, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3369, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2634, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3680, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4797, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2634, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3622, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5419, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2236, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5984, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1623, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4074, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2281, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4762, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3711, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1748, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2624, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1668, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2691, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1655, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3168, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2533, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2927, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3632, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1975, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2863, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2952, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4914, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2282, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3935, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2457, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3094, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3099, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3264, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3912, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3264, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2942, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4221, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3427, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4643, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2898, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3155, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3079, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5529, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3367, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3004, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1731, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2542, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5032, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2820, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5298, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3480, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3649, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3014, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3739, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2639, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2352, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2793, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3227, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2551, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4059, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3049, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2739, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3338, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3165, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5302, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4531, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3841, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5732, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3497, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2128, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3521, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2324, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4788, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1925, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4869, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4198, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1610, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1961, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3154, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2418, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4092, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4506, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3389, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3588, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3562, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3535, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3763, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2470, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3853, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3136, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2005, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2907, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3014, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3283, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1827, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1820, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5498, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4437, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2760, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3667, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4917, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3923, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2805, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3875, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3863, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3312, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3465, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2856, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3818, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2786, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4029, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2804, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3279, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3360, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1858, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3769, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2247, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3831, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1837, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5174, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3097, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2291, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3016, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2410, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3479, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3361, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2599, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2110, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2776, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3203, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3018, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2680, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2409, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1858, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3219, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3209, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1943, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4162, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3340, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3822, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3398, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4167, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4014, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3831, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3539, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3169, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3291, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2901, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1280, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1927, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4004, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.6182, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2818, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4119, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2573, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2718, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2991, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4749, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3785, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2927, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3302, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3472, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1881, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3167, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3312, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3484, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1793, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.6014, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2244, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3768, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2939, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2473, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5461, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3246, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1684, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5026, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2180, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2490, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2317, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3523, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2356, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3041, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3059, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4581, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4588, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4316, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3872, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2762, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.6563, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3778, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2946, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3070, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1386, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2709, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2627, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3738, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5707, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3113, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2174, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3084, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4286, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2838, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4447, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3052, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4134, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2688, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2231, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3952, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3306, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1956, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5325, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5218, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2698, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2105, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4069, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5512, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4468, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3390, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3763, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3604, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2770, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5049, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1660, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3464, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4577, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2532, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2572, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3617, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2070, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2210, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3415, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2358, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3891, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2891, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2086, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1480, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3850, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2779, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3260, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3210, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4768, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3101, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2393, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2488, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2482, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3401, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2288, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1934, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1442, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4479, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2656, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2397, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2253, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2992, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1952, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3351, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3599, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3348, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4026, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3758, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3070, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3128, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3878, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1920, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2836, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2866, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3289, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1975, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3549, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3461, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4202, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2106, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3616, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2712, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3379, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4167, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3346, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2739, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4196, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3314, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4379, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2904, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4592, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4920, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2800, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2609, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3519, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2932, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2220, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2191, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3320, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2471, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2671, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4718, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2244, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3366, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4788, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4427, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3034, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3112, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2722, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2554, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2407, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3880, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4256, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3038, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3745, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1825, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1780, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1365, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4292, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3299, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2891, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.6030, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4515, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3635, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4807, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2638, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3413, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2678, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3257, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2585, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2950, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3245, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2558, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2132, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2597, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3011, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2527, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3052, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4574, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2859, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2630, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3877, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3838, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2043, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4303, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3239, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4216, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4598, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1727, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3881, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2246, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3172, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4332, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1771, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2864, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2960, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3254, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2967, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1506, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3263, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3313, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3361, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.6005, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2858, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2914, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2640, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2806, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2991, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3687, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2950, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4318, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3500, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3810, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2592, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4240, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2266, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1733, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3734, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3071, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4338, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5988, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2005, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4715, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2730, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2739, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4239, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2814, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2826, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2143, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2487, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4111, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4243, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1777, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3281, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5360, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3676, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2040, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3995, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2481, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2631, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2497, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4288, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5606, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2649, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1138, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2676, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2657, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4205, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5495, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2462, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4348, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2959, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3226, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4318, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2847, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3195, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3683, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2794, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2696, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1967, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3047, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3092, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2480, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1907, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4930, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3138, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3089, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3743, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2823, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3450, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3295, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4181, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2174, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1658, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3387, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2242, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3913, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2992, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2855, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2873, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2763, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2844, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2627, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3445, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2242, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2558, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.6273, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1256, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2551, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5604, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2275, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3039, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2568, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1837, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2110, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4142, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1259, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3668, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1445, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3176, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2956, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2756, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3118, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3559, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3312, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2425, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3557, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2474, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2862, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2027, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3395, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4225, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2439, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3655, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2779, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3505, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3628, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2452, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2368, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2634, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3334, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2329, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4786, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2582, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1731, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2401, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2162, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1671, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2128, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1929, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2469, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4586, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3031, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3484, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3089, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2251, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3232, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3745, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4318, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2843, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2924, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4793, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3529, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3997, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3421, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4125, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3925, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2818, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3070, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2547, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1679, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.6807, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2837, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1522, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3458, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1842, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3702, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3244, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1702, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2375, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3386, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4029, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1865, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2193, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4064, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3811, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1716, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3638, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2582, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1994, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2515, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3320, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4388, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2095, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2330, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1107, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.6369, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2021, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3041, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3897, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2198, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1873, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.6423, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2500, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2666, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2266, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2174, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3111, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1444, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2214, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3046, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3395, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3545, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3533, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2228, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2449, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3864, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3045, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2371, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5555, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4841, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3044, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3197, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3485, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3278, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2882, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1504, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2673, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4020, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2548, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2584, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4621, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3238, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2780, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3465, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3849, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2474, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2204, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2968, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2457, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3355, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3427, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3377, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1265, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3150, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4372, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2276, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3883, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2983, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3685, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3248, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3398, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5470, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1467, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2606, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3300, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3406, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3287, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2635, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4961, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4219, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3785, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3215, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3522, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3537, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1923, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2092, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2455, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4354, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4156, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2269, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3818, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3291, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3450, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2365, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2718, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1982, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1501, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1782, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2091, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2323, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3503, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4055, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5120, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3800, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4824, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3982, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3485, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2498, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2824, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4454, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2659, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4060, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3112, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2641, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2364, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2601, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4784, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4767, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2968, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3541, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2083, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5169, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3053, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3114, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4971, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3304, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4482, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3149, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2132, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2741, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2347, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4652, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2287, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4540, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2889, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3436, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3646, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2694, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1702, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1595, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2977, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2134, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1812, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2445, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3095, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3567, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3325, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4130, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3057, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2519, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4027, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3519, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3791, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2371, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1543, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2619, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2570, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1875, grad_fn=<NllLossBackward>)\n",
            "Epoch 11 - Training loss: 0.32101143709918073\n",
            "loss: tensor(0.3549, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2171, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2936, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2125, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2601, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2610, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.7000, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3332, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4013, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2327, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2493, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2654, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2608, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1644, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3172, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3362, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2969, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2052, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2920, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2920, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3960, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3375, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2588, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3410, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2552, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3676, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4057, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2261, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3458, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4406, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2964, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3814, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2104, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2404, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2934, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1976, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2871, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2543, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3102, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4803, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2105, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3113, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2459, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2658, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1650, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1750, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2189, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1676, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3111, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2631, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2066, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3205, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3059, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1710, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1400, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3314, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5249, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1887, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3168, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1942, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1579, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3805, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2822, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4023, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2724, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3103, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3347, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2203, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4789, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2672, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3568, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3288, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2982, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3626, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2354, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4271, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2164, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3415, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3173, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1394, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2471, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2167, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4290, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2485, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4345, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3235, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5950, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2607, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2765, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3565, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3323, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3834, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.6519, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4037, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5669, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2710, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2554, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2925, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2677, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4762, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1939, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3452, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3016, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3423, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2509, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2337, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3648, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2005, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4702, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1564, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3342, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3449, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2140, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3420, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2025, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5783, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2615, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2305, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2584, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5336, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3228, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3313, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1885, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3361, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2096, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2695, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2150, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5391, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1696, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4013, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4016, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3412, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1970, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2442, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1892, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1916, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3069, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5169, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3188, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2229, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3311, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5011, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3003, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2727, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1409, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2310, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2230, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2721, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3664, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5253, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1411, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2492, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3371, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3894, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3649, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2373, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2399, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1961, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3159, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4558, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3217, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5029, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1653, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.6026, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2787, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5156, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3492, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2954, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4581, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2209, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4805, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2763, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2249, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2038, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3623, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2550, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4724, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2699, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1918, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2936, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5646, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2919, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4342, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4865, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1640, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4621, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1880, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4511, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3175, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1480, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3408, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1587, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5196, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4785, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2935, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3273, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4057, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1987, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3464, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1684, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4067, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2323, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3767, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3496, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3856, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3997, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2358, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3060, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4567, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2581, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1870, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2537, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3479, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3302, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2867, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3548, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2478, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5378, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3599, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3358, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2815, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2827, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5718, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4356, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3617, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4772, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3772, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3580, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2839, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1561, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2141, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4401, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3133, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3050, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4494, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3961, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2181, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4177, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3375, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5056, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2423, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2255, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3384, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2351, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2524, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1924, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3233, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2700, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2594, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5033, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1670, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1738, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3214, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4200, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4726, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4988, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3914, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3578, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3919, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3008, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4110, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3456, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3411, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4109, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1732, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2037, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2968, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3043, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3635, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2910, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1793, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1204, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.6566, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4258, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1838, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2003, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1979, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3473, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2610, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4895, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1301, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1917, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3050, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2357, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3450, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3054, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3962, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5833, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1957, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2066, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1990, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3433, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2571, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2418, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3001, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4342, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1984, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2511, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2186, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3717, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4601, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2518, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1786, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3638, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2886, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3456, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5001, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4905, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4230, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2261, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4540, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2475, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3178, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1783, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2508, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2724, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2951, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3080, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3128, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2256, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4565, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3307, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2830, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1817, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3039, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3315, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2745, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5588, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1480, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3212, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4716, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1484, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2116, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3801, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4651, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2264, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3646, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3284, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3092, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2559, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4220, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3349, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3792, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2374, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1484, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3736, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4366, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3633, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4456, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5278, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2515, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2462, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1762, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3561, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4280, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2682, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3169, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3987, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2684, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4881, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2360, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3374, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2531, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3984, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4311, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2034, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2842, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3639, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5156, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2677, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3271, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3766, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1783, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.6159, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4160, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4443, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1007, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3755, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3236, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3816, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2963, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3813, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2924, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2381, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3574, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3653, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2243, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3212, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4319, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2065, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2841, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4205, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5343, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2524, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3109, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1850, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5478, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2600, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1894, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2941, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2644, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4772, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4674, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5439, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4480, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5402, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3269, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4349, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3778, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3782, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2544, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3859, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1417, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3014, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3748, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1797, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1306, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2535, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2211, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2370, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3272, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4402, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4597, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2731, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5583, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5110, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2656, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2734, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2837, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2742, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1846, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4140, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2575, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1863, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3199, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3968, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1949, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3417, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3189, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2712, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2740, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2137, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1983, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4804, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2435, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1411, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1821, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3882, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2012, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2833, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3223, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3526, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3025, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3168, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2156, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3374, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1775, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3756, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2185, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3378, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3070, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2625, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1614, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3446, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3142, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2518, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3626, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4755, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2105, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1829, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4152, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4266, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2791, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3466, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3526, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2713, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1829, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2845, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2318, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2539, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2038, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4097, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4087, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3457, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2092, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1362, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3621, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4038, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2650, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4422, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3243, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3068, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2523, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3313, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3503, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4524, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5302, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2470, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2192, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2832, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3332, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2897, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4109, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2480, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4256, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1718, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1416, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1319, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3314, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4348, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3475, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5297, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3965, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4096, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3478, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4226, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1870, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2789, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4723, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1369, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2398, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5610, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4249, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4358, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1341, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2530, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4443, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3174, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2893, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3297, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3101, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2949, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2486, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5426, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2370, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3671, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3129, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2033, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4583, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2724, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2852, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4009, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4355, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2180, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2358, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3672, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3398, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3730, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2945, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4448, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2340, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2125, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2312, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3425, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3131, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1935, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2691, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1490, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2470, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3688, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5473, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2682, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2132, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1999, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4353, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3375, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4153, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3030, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4874, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4463, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4813, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4846, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2377, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2867, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5631, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3743, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1709, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5263, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5927, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2690, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1493, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2926, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4824, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3077, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4590, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2006, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2472, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1295, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2971, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2649, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3669, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2553, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2505, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1894, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2788, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3662, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2722, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3138, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2871, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3681, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2318, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1235, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2529, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2488, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4681, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2325, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1872, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3147, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2955, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1664, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3648, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3073, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4271, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3777, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3110, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2596, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3159, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1868, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2640, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3321, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2400, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1162, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3145, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4438, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2581, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1460, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4063, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4347, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2505, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3393, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3372, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3830, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2688, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5088, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3771, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2512, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1928, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2592, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1899, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3408, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2683, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2681, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4269, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.6708, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2012, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2226, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1575, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2380, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3452, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2501, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2375, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2454, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3502, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3320, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1762, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3352, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1638, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2991, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2711, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3091, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3600, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3035, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1912, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4365, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2544, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2903, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3077, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2574, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2336, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3512, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4061, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2395, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4901, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4182, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2496, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2038, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2779, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2266, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3213, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2660, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2628, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3792, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2196, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3351, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1760, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2129, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2274, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3262, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2368, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4765, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3550, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3649, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.6853, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3597, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4270, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2349, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1990, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2878, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3850, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.0981, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2720, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5188, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3260, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1988, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2792, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4434, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2425, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4024, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3086, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2934, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4036, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3728, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2332, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2313, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1851, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3197, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2860, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2510, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2127, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4714, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3210, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5142, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3757, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3205, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3205, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4472, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3654, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3920, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2113, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4343, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1613, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3085, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2595, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2578, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3852, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2500, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2886, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3298, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2918, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2580, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2964, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3337, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3014, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3068, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1987, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1651, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2482, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3028, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3805, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4708, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3652, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3256, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2086, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3815, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3709, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2731, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3290, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2066, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5099, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3010, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.6118, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3079, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4796, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3461, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3030, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3652, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3456, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2711, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1455, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3274, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3421, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3018, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4330, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2634, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3575, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2677, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2156, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3842, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4702, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4438, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2973, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3223, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3297, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4895, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3388, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2254, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2879, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3866, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2862, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1496, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2782, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2545, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3378, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4049, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3837, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4577, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3905, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1264, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3538, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2348, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2386, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4289, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2365, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2106, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2754, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2620, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2531, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2438, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1947, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2066, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3517, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2653, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1518, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3314, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1035, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2135, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2192, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1751, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2524, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2718, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2081, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2504, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2816, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3618, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2930, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2691, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1842, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4561, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2310, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3660, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2332, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4057, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3179, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2284, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3943, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4626, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2344, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3391, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4520, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1116, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2483, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3417, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4165, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1921, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4183, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2348, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2431, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4340, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2433, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4453, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2383, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3038, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3402, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2599, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1672, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2824, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3177, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3119, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3156, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2501, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3842, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3523, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2896, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3114, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2626, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2661, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4436, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3917, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3727, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3820, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1517, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4281, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3444, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4123, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2680, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3993, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2590, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4859, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4562, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2428, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2498, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3385, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3299, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3126, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4344, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2437, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2687, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4165, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2987, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1713, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2586, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1359, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2080, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4406, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3162, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1780, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1432, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4746, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2104, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2218, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2471, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1917, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2144, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5239, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2952, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3245, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2921, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1793, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2334, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2608, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2953, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1903, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3668, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2473, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3398, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2788, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2399, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2175, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2654, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2282, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2459, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3686, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1640, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2672, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3300, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1776, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2386, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3883, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4167, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3218, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1017, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2438, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3796, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1685, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3755, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3478, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2798, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.7216, grad_fn=<NllLossBackward>)\n",
            "Epoch 12 - Training loss: 0.31311588251450934\n",
            "loss: tensor(0.3862, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2207, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2869, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2372, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3481, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2433, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2212, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5182, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2172, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1802, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2211, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3811, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2553, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4955, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2383, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2155, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3427, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2982, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2708, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.6631, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3277, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3520, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1867, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2415, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4839, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3219, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4054, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4887, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4749, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2740, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3423, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3098, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3547, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3975, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2602, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3827, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4890, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3375, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2906, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4992, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2604, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3216, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3558, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1882, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2378, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2892, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3489, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2291, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1526, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3659, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2587, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3710, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2375, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2651, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3007, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2514, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3087, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3519, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5875, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4568, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2414, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3004, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1709, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3273, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4085, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2350, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2437, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3175, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3284, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2242, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1801, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3217, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4393, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2448, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4060, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1412, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4213, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3979, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3021, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3166, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3221, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2305, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1782, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2816, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2587, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4865, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4942, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3195, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2391, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3129, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2805, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3168, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3197, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1876, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3855, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5712, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3249, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5246, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2087, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3138, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2879, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4260, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3012, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3033, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1493, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2721, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3033, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4408, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2758, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4922, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4149, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3885, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2054, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2873, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2470, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3895, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2330, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1875, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2946, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2914, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2896, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1527, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3762, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2599, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.6980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3565, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2341, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4280, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4484, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3260, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2287, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3241, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3248, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4369, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2470, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2921, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2507, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2792, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3498, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2138, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2334, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3238, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3894, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2254, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2695, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2620, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3194, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1982, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3452, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3092, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5303, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3733, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4261, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4975, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2671, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3170, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2037, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3294, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4198, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3032, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2792, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2918, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5096, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3381, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3917, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4185, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2490, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2681, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2326, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5268, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2120, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3443, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2588, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2820, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2220, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4066, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4047, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2690, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3647, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2263, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3439, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4892, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2288, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4843, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2034, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4433, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3279, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3438, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3607, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2024, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2856, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2692, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3048, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2755, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5776, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1379, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3128, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2706, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1938, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3922, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2370, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2286, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2149, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2470, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2933, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1711, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2886, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3591, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5495, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2879, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3417, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2612, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3187, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4293, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1512, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3277, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2738, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2001, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3392, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3230, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3655, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3160, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2860, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4168, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3410, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3791, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3170, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3557, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3025, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1587, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3650, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3190, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4720, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3004, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3620, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3270, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2999, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1383, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3384, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3877, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3348, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3892, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2944, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3430, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2489, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3353, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3515, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3113, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.6417, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2955, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3435, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2511, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4224, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4027, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2192, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4242, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2562, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5217, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2670, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3281, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1553, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2384, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3890, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5213, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2464, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2289, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.6344, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3050, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4137, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3425, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2762, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1556, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2538, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1958, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5966, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2084, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2602, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4179, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1369, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2591, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3440, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3429, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3196, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5317, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2140, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2844, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2292, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2536, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2888, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1112, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1849, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5032, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3214, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1962, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3039, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3218, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2833, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2854, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2376, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3065, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2017, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3151, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2894, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5340, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2705, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3720, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2957, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2755, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1637, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1997, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3474, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2383, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1909, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4118, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2144, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3158, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3630, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3107, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2390, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2067, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1610, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1997, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3867, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4162, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5315, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2339, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1978, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3164, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2605, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1156, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2785, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1797, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2929, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2314, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2304, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3546, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3551, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2617, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3137, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3190, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3884, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2125, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2052, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4399, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2587, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.6236, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3244, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1550, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3075, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2915, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2266, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1387, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4501, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3670, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4177, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2914, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2746, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4394, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2943, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3342, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3676, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1953, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3561, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3387, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3241, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1597, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3108, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3047, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2857, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2618, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4839, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2168, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4641, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3918, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3101, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2764, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3290, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2639, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4439, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4532, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2151, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2874, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2582, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1189, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4471, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1994, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2156, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3404, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5584, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3735, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3628, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2420, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2701, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3331, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2986, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4199, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2080, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4394, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2581, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3722, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2624, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3515, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2717, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2403, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3047, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3127, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1242, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2791, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2065, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2027, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2352, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3269, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2159, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3248, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5371, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1787, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3128, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2580, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2178, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3241, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3154, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2149, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2308, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2664, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2660, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4457, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3871, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4492, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2466, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1721, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3168, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4147, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2843, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3867, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2792, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2869, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1366, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2420, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3022, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2242, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2183, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2404, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2987, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4379, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2470, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1584, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2507, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2531, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1852, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1248, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1961, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4244, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2148, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2445, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2196, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1815, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1453, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3252, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3318, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2086, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2201, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2987, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1899, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3685, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2427, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2744, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2903, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3108, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2549, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5023, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4425, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3045, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3977, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3566, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1961, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2205, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3552, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3936, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2614, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2324, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3554, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4846, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2063, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2745, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4879, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4110, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2439, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3551, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3546, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2503, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1870, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3374, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4710, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2146, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4480, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2909, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5852, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2807, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2987, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3598, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3764, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2833, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1622, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1877, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2972, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3053, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3672, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3360, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4092, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2039, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1846, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4199, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1883, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1829, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1535, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3197, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3938, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4613, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3534, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3642, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2441, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3574, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2582, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5449, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3115, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1810, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3568, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2337, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1866, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2007, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3024, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3577, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2465, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2523, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2147, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2449, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2858, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2768, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3555, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2856, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2738, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3084, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2635, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3064, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3096, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3780, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2452, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1754, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2688, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4204, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2995, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3073, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1880, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2834, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1909, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1515, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3371, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5083, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2076, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2846, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2550, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4567, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1577, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2247, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2769, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2743, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2749, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3924, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2074, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4346, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3844, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3867, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2266, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3443, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3085, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2482, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1940, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2009, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2370, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3015, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3797, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2614, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4292, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2814, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2891, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4209, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5967, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2877, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1815, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1672, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4863, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2238, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3012, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3133, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.7119, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4451, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1711, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1503, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5623, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4154, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3772, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2832, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2828, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3782, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3449, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2972, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2187, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1704, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2599, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2966, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3516, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4162, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1923, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3769, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2020, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3439, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2083, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2117, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4100, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3539, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1799, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2357, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2639, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4187, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2955, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5407, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2801, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2735, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2229, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1813, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2793, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3207, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3251, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3756, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4258, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3015, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1982, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3020, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1949, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2410, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1410, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2039, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2968, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3090, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2406, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3993, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4059, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1791, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3573, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2172, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2968, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2535, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3130, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2944, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2356, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3086, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2964, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2912, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2719, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1306, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2413, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4372, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2637, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3603, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2499, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2112, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.6059, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2254, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2525, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2292, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3943, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1055, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2756, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2618, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4004, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3426, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2268, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3170, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2364, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3440, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2338, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2511, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2025, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3323, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2934, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4227, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3175, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2979, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2714, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1925, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3063, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2761, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3033, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2676, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3718, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3497, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2623, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3295, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2650, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1132, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4541, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2279, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1872, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2886, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3923, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4211, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4099, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3765, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1791, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3896, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2599, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3360, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1764, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2191, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4139, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2491, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4328, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3224, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3157, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2923, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3614, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1857, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2705, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2597, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3644, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2066, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3221, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2944, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2381, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4472, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3020, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3184, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3584, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1601, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2511, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3511, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2411, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2088, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4748, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3414, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3743, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2373, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2557, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5722, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3841, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3330, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3018, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5121, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4132, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2385, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1994, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4230, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3909, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2900, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4798, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5362, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2096, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1834, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1442, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1446, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2139, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2323, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2620, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4296, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2762, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4390, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2583, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2440, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2529, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1531, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4411, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2793, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2174, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3413, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4121, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1435, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1993, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2812, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2911, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2653, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1552, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2198, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3703, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2855, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2274, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1701, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1664, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4742, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3900, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2668, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1584, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3918, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2811, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3041, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2546, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3080, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3356, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3592, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3541, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2170, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3520, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1187, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2116, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2884, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3274, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3525, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3659, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2432, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2767, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1855, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2043, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2899, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2664, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2253, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4092, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4189, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3136, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3604, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3982, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1213, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3061, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2472, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2773, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3841, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2763, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4109, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3287, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1558, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3902, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2339, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2116, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2305, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2281, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3529, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5603, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2562, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2127, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3770, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3789, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4028, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2704, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3496, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2627, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2845, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4292, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1332, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2162, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2943, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4623, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2804, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2445, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3107, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3752, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2904, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2321, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1705, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3347, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2416, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1957, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3983, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3550, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1874, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2783, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3929, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3714, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3500, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3129, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2431, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2106, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4378, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2485, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2487, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1661, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4062, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3984, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2267, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3523, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2805, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3050, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3762, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2388, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3570, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3916, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2697, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3450, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4808, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1424, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1975, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4212, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1355, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3174, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2142, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2636, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2294, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1207, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2529, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1929, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3391, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4293, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3362, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2497, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1671, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1909, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2422, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3277, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4109, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1392, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3515, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2157, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2542, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2343, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1452, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2430, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4902, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2537, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3275, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3608, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2848, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3286, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3324, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2895, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3965, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4570, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2940, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2174, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2569, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2377, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5204, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5596, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4157, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2728, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3284, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3329, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3035, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5712, grad_fn=<NllLossBackward>)\n",
            "Epoch 13 - Training loss: 0.3057326784949186\n",
            "loss: tensor(0.2884, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2369, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3985, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4295, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3533, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3730, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3160, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3552, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3878, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2344, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1555, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2913, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2037, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2662, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2247, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2288, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3647, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2591, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2237, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4162, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2387, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3589, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3818, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2495, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1764, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3663, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2948, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3788, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2102, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1745, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3426, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3342, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3786, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2868, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1723, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1497, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3250, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3124, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3413, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2009, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5062, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3581, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2463, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2580, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5661, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1245, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4879, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1213, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2450, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2677, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4092, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3333, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3115, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3075, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4178, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2068, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2424, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2161, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4247, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3255, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1347, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.6957, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3074, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2017, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2831, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5021, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3958, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2390, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2460, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1629, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2565, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3738, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3962, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4130, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2187, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3853, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2379, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2896, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3142, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2221, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2636, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1750, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2624, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1876, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2131, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2080, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2867, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2887, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4666, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1976, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1574, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4113, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2593, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2486, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1217, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1939, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3220, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3055, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2675, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2261, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3965, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4261, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5985, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4240, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4293, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3629, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2968, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2721, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2112, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1957, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3330, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2901, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4657, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2483, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2839, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2210, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2295, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2870, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1979, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3252, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3937, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4287, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2316, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1987, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2442, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4515, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2989, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3742, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1038, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4824, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2472, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3170, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1351, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4219, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2621, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3620, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2587, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3524, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3454, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3423, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4064, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3313, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3818, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3937, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3101, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5854, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2519, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4039, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2199, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2048, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4743, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1951, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2868, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1972, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2748, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2058, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1413, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3564, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2937, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3250, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1837, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3646, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2957, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2958, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5016, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2667, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2532, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2037, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3043, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4388, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2653, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1923, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4841, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4129, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2492, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1931, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2460, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2301, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2306, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3328, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3709, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2589, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2364, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5575, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2335, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4625, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5230, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3471, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2256, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2527, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1891, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3622, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5050, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1721, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3590, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2742, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4355, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3655, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2930, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1912, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4705, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1902, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3525, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3393, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3131, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4846, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1358, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4297, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1667, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1996, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2877, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2998, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1247, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5466, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1801, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2272, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2165, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3059, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3104, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2877, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3797, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2663, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3457, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3019, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4228, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2937, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1198, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2433, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1364, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3182, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2926, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4584, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1114, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4278, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2243, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3153, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2971, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3784, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2396, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1487, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3371, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2467, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2196, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2804, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4081, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2190, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3419, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2913, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3813, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3038, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2648, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4307, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2329, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3447, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3077, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.6551, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2293, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4439, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2427, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2330, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3016, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3013, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3056, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3966, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2578, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3806, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5277, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4049, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1976, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2724, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3764, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2564, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3036, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3131, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3256, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2842, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2492, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1630, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4037, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2355, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2692, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2982, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4588, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2322, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1993, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2042, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1607, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3276, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3235, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2028, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2654, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3679, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3442, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5295, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2586, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3743, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3947, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2730, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2210, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2086, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3805, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3231, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3542, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2583, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1890, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2600, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2868, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5034, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5002, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3988, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3356, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1844, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4799, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2588, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2582, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3617, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3498, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3040, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2558, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3257, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4348, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4083, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1879, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2962, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4551, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2724, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2325, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4009, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2517, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2345, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2541, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3782, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3139, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2251, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2308, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1777, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3324, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4196, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2963, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1908, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2088, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1765, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2261, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2256, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2697, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2009, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4377, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2494, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4885, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2541, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1400, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2657, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3242, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2146, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3373, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2145, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3304, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2511, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3316, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2586, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4540, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3076, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4201, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3790, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2571, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1703, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2762, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5363, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1955, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1893, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2229, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3419, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1459, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4486, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3564, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1847, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1821, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5113, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2607, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3045, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1978, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3108, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3782, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4092, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4689, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4089, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2288, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3944, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2781, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3493, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1765, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5493, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4416, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3289, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2761, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2281, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4252, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1448, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1242, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1778, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2235, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3472, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1689, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3393, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2007, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3146, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4617, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4975, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5763, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2034, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1957, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3076, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3694, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3267, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3329, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2259, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2087, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4309, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3756, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3478, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4348, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4179, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2660, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2738, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2284, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3872, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2197, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2245, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2575, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1422, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3133, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3123, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2244, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1596, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3320, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1463, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2089, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2523, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5229, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3123, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2002, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4446, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2927, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4487, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4250, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3483, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3151, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2703, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3198, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1208, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5426, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4436, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3251, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1877, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2075, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3289, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1858, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3875, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5380, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3514, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3350, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1947, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2625, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3057, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3287, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2123, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.6114, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2476, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3757, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3740, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2067, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4851, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3199, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2530, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3857, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.6574, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3680, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5062, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3597, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3475, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1864, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1857, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1827, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3260, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2307, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3257, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3610, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2952, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1619, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3006, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3759, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1822, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2210, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5605, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3306, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2782, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3266, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2802, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4592, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2348, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5590, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1446, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3252, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4843, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2102, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1577, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2453, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2545, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2245, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3612, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3960, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2486, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1658, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4221, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2338, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5590, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5356, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1315, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3821, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3085, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2222, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2647, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1680, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3842, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2741, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2937, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3068, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3490, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2709, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4134, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.0966, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2760, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2369, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3410, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2395, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3289, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3742, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3618, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3916, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3891, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1723, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5873, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3828, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2384, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3154, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2207, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3339, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4272, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1173, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3824, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2909, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3417, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2846, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1630, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2741, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2804, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2201, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5095, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3188, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2154, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2027, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1517, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2383, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1957, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4471, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2328, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2620, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5435, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3316, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3293, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4631, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4477, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.0928, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2308, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1105, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2038, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2725, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4904, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2570, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1999, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2071, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3591, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4756, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2670, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2865, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2721, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2763, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3014, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2825, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3306, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3462, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2859, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2262, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1514, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3686, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1860, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1272, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3363, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3794, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3885, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1950, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2867, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2434, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2545, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3333, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2258, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3646, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3259, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1593, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2996, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2927, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4011, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3128, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2078, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3616, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4143, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2234, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2185, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3204, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2800, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3183, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2805, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4508, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2140, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2021, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2406, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1318, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2435, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3883, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3498, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2797, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2523, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3812, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2398, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3335, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3328, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3412, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1779, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2929, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3515, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3419, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2728, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2692, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1583, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3330, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2018, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2003, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2631, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3378, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4292, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1695, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2616, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2838, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1605, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2721, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3624, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2276, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3658, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3122, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2860, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1688, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3102, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3057, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2358, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2719, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2936, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2933, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3922, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4548, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2590, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4383, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1410, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2182, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3681, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3162, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2894, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2063, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3245, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2627, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3186, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3069, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3509, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3169, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2979, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1808, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1313, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2523, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1743, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2443, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2348, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1589, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4074, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2011, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2207, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2797, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2722, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2783, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1317, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1171, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2998, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1876, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2629, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2585, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1684, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3193, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3486, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1537, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2012, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2559, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2034, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4323, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3001, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2090, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3241, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2264, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5370, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2666, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2865, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3464, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2964, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4378, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3576, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2655, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1884, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2896, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1831, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5750, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3665, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2714, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1774, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1714, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2758, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3338, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1191, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4382, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2081, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3349, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3382, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2946, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1401, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2158, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2647, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4133, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3740, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3795, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2356, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3486, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4147, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2331, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3657, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4457, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5374, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2524, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2694, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4253, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3158, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3118, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3388, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5186, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3483, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2230, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3177, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3055, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2865, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3940, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2027, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3130, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2919, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5061, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2593, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2901, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3982, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3638, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3666, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5469, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2585, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1490, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2911, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2335, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3873, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5062, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2332, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2470, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2255, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1719, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2428, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3067, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2504, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3432, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4690, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2945, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3767, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2259, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2288, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2897, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2452, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3685, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3500, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2564, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2189, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2512, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4527, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1352, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2968, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3033, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1916, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2760, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2430, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2589, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3217, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2902, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2548, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3522, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2393, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2656, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4692, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3515, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2428, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4527, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2090, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3522, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2464, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2086, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1521, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1310, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2148, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3066, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1900, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3231, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1219, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3720, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4397, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1431, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1973, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3097, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2797, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3363, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3143, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4557, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2361, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4625, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3067, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2546, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2795, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5474, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2388, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3283, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2581, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3449, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3967, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3219, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2347, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.7030, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2408, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4523, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1582, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3663, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4651, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1801, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1619, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1869, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2354, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2473, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3411, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2298, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3164, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3363, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1993, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2738, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2405, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2676, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1884, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2599, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2455, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2247, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4093, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2329, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2754, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1535, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2268, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1651, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1633, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3959, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2005, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2900, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2349, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1754, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2594, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1060, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2851, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4935, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3465, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2452, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2245, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3366, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2071, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3228, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2940, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2726, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2607, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2587, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3139, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1692, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4037, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3131, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2652, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1875, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2046, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3478, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1851, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2305, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3032, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4647, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1670, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2850, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2726, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2791, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2403, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.4077, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2847, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2068, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2557, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3051, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1253, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2069, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1926, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2027, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2877, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.3286, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.5338, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2807, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1720, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2985, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.1534, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "Epoch 14 - Training loss: 0.29876479678856793\n",
            "\n",
            "Training Time (in minutes) = 3.829089403152466\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1nXRTCObswa"
      },
      "source": [
        "Run the cells below to show the image and class probabilities that were predicted"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDKA8rX_cpCf"
      },
      "source": [
        "def view_classify(img, ps):\n",
        "    ''' Function for viewing an image and it's predicted classes.\n",
        "    '''\n",
        "    ps = ps.data.numpy().squeeze()\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n",
        "    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n",
        "    ax1.axis('off')\n",
        "    ax2.barh(np.arange(10), ps)\n",
        "    ax2.set_aspect(0.1)\n",
        "    ax2.set_yticks(np.arange(10))\n",
        "    ax2.set_yticklabels(np.arange(10))\n",
        "    ax2.set_title('Class Probability')\n",
        "    ax2.set_xlim(0, 1.1)\n",
        "    plt.tight_layout()"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8vC4C1vbr-C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "outputId": "087c7043-2759-46e2-de5a-052aec92fae3"
      },
      "source": [
        "images, labels = next(iter(valloader))\n",
        "\n",
        "img = images[0].view(1, 784)\n",
        "with torch.no_grad():\n",
        "    logps = model(img)\n",
        "\n",
        "ps = torch.exp(logps)\n",
        "probab = list(ps.numpy()[0])\n",
        "print(\"Predicted Digit =\", probab.index(max(probab)))\n",
        "view_classify(img.view(1, 28, 28), ps)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted Digit = 9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhSmJfe8b3Zy"
      },
      "source": [
        "Now we iterate through the validation set using a for loop and calculate the total number of correct predictions and then calculate the model accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqWE7ZK5b7TR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d958524-4020-434b-c23f-9c94c51a2ce8"
      },
      "source": [
        "correct_count, all_count = 0, 0\n",
        "for images,labels in valloader:\n",
        "  for i in range(len(labels)):\n",
        "    img = images[i].view(1, 784)\n",
        "    with torch.no_grad():\n",
        "        logps = model(img)\n",
        "\n",
        "    \n",
        "    ps = torch.exp(logps)\n",
        "    probab = list(ps.numpy()[0])\n",
        "    pred_label = probab.index(max(probab))\n",
        "    true_label = labels.numpy()[i]\n",
        "    if(true_label == pred_label):\n",
        "      correct_count += 1\n",
        "    all_count += 1\n",
        "\n",
        "print(\"Number Of Images Tested =\", all_count)\n",
        "print(\"\\nModel Accuracy =\", (correct_count/all_count))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number Of Images Tested = 10000\n",
            "\n",
            "Model Accuracy = 0.9158\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGNfcRp1c0dp"
      },
      "source": [
        "Now that we have learnt how to work with image data and we have a baseline for our neural network, we want you to try to achieve a good accuracy by training a model for different hyperparameters. Use the same code as above for your experiment. You are free to experiment with different values for the learning rate, use different optimizer instead of SGD, use different loss function, add extra layers to your network, etc. Try out your experiments and keep the final set of hyperparameters. Display the accuracy for your custom model. If interested you can also try adding dropout layers to your model to see if model performs better."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1X01OsUue3wE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5942d35a-8ad7-4520-e0e4-cdc5ecf0b0e7"
      },
      "source": [
        "# TODO: Add your code here (5 marks)\n",
        "\n",
        "model = nn.Sequential(nn.Linear(784,256),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(256,64),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(64,10),\n",
        "                      nn.LogSoftmax(dim=1))\n",
        "\n",
        "optimizer1 = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.5) \n",
        "\n",
        "time0 = time()\n",
        "epochs = 15\n",
        "\n",
        "for e in range(epochs):\n",
        "    running_loss_1 = 0\n",
        "    for images, labels in trainloader:\n",
        "        images = images.view(images.shape[0], -1)\n",
        "        optimizer1.zero_grad()\n",
        "        output1 = model(images)\n",
        "\n",
        "        loss1 = criterion(output1, labels)\n",
        "        print('loss:',loss)\n",
        "        loss1.backward()\n",
        "        optimizer1.step()\n",
        "        running_loss_1 += loss1.item()\n",
        "    else:\n",
        "        print(\"Epoch {} - Training loss: {}\".format(e, running_loss_1/len(trainloader)))\n",
        "print(\"\\nTraining Time (in minutes) =\",(time()-time0)/60)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "Epoch 9 - Training loss: 0.3418873675119902\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "Epoch 10 - Training loss: 0.33093335365117993\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "Epoch 11 - Training loss: 0.32156620105541844\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "Epoch 12 - Training loss: 0.31354189346403455\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "Epoch 13 - Training loss: 0.3064780778436264\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "loss: tensor(0.2980, grad_fn=<NllLossBackward>)\n",
            "Epoch 14 - Training loss: 0.30008637879703093\n",
            "\n",
            "Training Time (in minutes) = 4.023655502001445\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "McCNl8AK376E",
        "outputId": "9da5689c-32a8-4fd7-b434-44e9d7adacf6"
      },
      "source": [
        "correct_count, all_count = 0, 0\n",
        "for images,labels in valloader:\n",
        "  for i in range(len(labels)):\n",
        "    img = images[i].view(1, 784)\n",
        "    with torch.no_grad():\n",
        "        logps = model(img)\n",
        "\n",
        "    ps = torch.exp(logps)\n",
        "    probab = list(ps.numpy()[0])\n",
        "    pred_label = probab.index(max(probab))\n",
        "    true_label = labels.numpy()[i]\n",
        "    if(true_label == pred_label):\n",
        "      correct_count += 1\n",
        "    all_count += 1\n",
        "\n",
        "print(\"Number Of Images Tested =\", all_count)\n",
        "print(\"\\nModel Accuracy =\", (correct_count/all_count))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number Of Images Tested = 10000\n",
            "\n",
            "Model Accuracy = 0.9183\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}